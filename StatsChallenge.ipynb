{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfuOFJw7Ocau/ylttx7Wf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/martingale/blob/main/StatsChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M58DZAwZb8j",
        "outputId": "1b744d1a-dccc-4f7c-8529-9f990f4b2f40"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/microprediction/martingale.git\n",
            "  Cloning https://github.com/microprediction/martingale.git to /tmp/pip-req-build-th6lk813\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microprediction/martingale.git /tmp/pip-req-build-th6lk813\n",
            "  Resolved https://github.com/microprediction/martingale.git to commit a18efb5d63d27962852d5b6ad429875d23933b0d\n",
            "\u001b[31mERROR: git+https://github.com/microprediction/martingale.git does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PREAMBLE = \"\"\" # You are being asked to write a class with the following methods:\n",
        "    #\n",
        "    #  get_mean(self):        Returns an estimate of a latent variable\n",
        "    #  update(x:float):       Assimilate information from a noisy observation x\n",
        "    #\n",
        "    #  The approach you write should work reasonably well for the following examples:\n",
        "    #\n",
        "    #            - Brownian motion observed with noise\n",
        "    #            - Brownian motion observed with serially correlated noise\n",
        "    #            - Time-subordinated brownian motion observed with serially correlated noise\n",
        "    #            - Time-subordinated brownian motion observed with serially correlated noise and occasional large outliers\n",
        "    #\n",
        "    #  You should make no assumptions about the scale of the process or the ratio of fluctuations\n",
        "    #  caused by Brownian motion to those caused by the noise process.\n",
        "    #\n",
        "    #  The construction should not receive any arguments. Everything must be learned on the fly. You should try to learn\n",
        "    #  as much as possible about the process as quickly as possible in order to create a robust nowcast that works well\n",
        "    #  whether we see 100 observations, 5000 observations, or 100,000 observations.\n",
        "    #\n",
        "    #  The class must be called \"Nowcast\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "59JBoI7SVBKp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt\n",
        "(Initial prompt to LLM)"
      ],
      "metadata": {
        "id": "y2ROe0D3VtAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def challenge_prompt():\n",
        "    \"\"\"\n",
        "    Returns a prompt that includes the PREAMBLE and the definition of NowcastExample.\n",
        "    \"\"\"\n",
        "    nowcast_example_code = \"\"\"class NowcastExample:\n",
        "    def __init__(self):\n",
        "       # Initialize state as you see fit here\n",
        "       self.prev_x = None\n",
        "\n",
        "    def update(self, x:float, dt:float):\n",
        "       # Upon receiving value x dt ms after the previous value, update the state\n",
        "       self.prev_x = x\n",
        "\n",
        "    def get_mean(self):\n",
        "       # Provide a nowcast of the mean of the anchor state\n",
        "       return self.prev_x\n",
        "\"\"\"\n",
        "    # Combine the PREAMBLE with the example code\n",
        "    combined_prompt = PREAMBLE + nowcast_example_code\n",
        "    return combined_prompt\n",
        "\n",
        "challenge_prompt()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "rClclxYwYPy7",
        "outputId": "fc9a96a4-241b-43e8-e20a-afff2e5b9342"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' # You are being asked to write a class with the following methods:\\n    #\\n    #  get_mean(self):        Returns an estimate of a latent variable\\n    #  update(x:float):       Assimilate information from a noisy observation x \\n    #\\n    #  The approach you write should work reasonably well for the following examples:\\n    #\\n    #            - Brownian motion observed with noise\\n    #            - Brownian motion observed with serially correlated noise\\n    #            - Time-subordinated brownian motion observed with serially correlated noise\\n    #            - Time-subordinated brownian motion observed with serially correlated noise and occasional large outliers\\n    #\\n    #  You should make no assumptions about the scale of the process or the ratio of fluctuations\\n    #  caused by Brownian motion to those caused by the noise process. \\n    #\\n    #  The construction should not receive any arguments. Everything must be learned on the fly. You should try to learn\\n    #  as much as possible about the process as quickly as possible in order to create a robust nowcast that works well \\n    #  whether we see 100 observations, 5000 observations, or 100,000 observations. \\n    #\\n    #  The class must be called \"Nowcast\" \\nclass NowcastExample:\\n    def __init__(self):\\n       # Initialize state as you see fit here\\n       self.prev_x = None\\n\\n    def update(self, x:float, dt:float):\\n       # Upon receiving value x dt ms after the previous value, update the state       \\n       self.prev_x = x\\n\\n    def get_mean(self):\\n       # Provide a nowcast of the mean of the anchor state \\n       return self.prev_x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put your actual nowcast example here:\n",
        "(Which might be the response from the LLM, or something you write)"
      ],
      "metadata": {
        "id": "yYbCCl2AVKVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Nowcast:\n",
        "    \"\"\"\n",
        "    A robust, adaptive nowcaster for a latent state observed with:\n",
        "      - Brownian motion\n",
        "      - Potentially serially correlated noise\n",
        "      - Occasional large outliers\n",
        "      - Unknown scale\n",
        "\n",
        "    Everything is learned on the fly. The time interval dt is used in\n",
        "    modeling the variance growth of the Brownian increment.\n",
        "\n",
        "    Example usage:\n",
        "    -------------\n",
        "    nc = NowcastRobust()\n",
        "    for t in range(len(data)):\n",
        "        # Suppose data[t] arrives after dt = 1.0, for simplicity\n",
        "        nc.update(data[t], dt=1.0)\n",
        "        estimate = nc.get_mean()\n",
        "        # do something with estimate\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # -- Adaptive State Estimates --\n",
        "\n",
        "        # 1) Latent state estimate:\n",
        "        self.x_hat = 0.0\n",
        "        self.has_first_obs = False\n",
        "\n",
        "        # 2) AR(1) noise estimate:\n",
        "        self.e_hat = 0.0\n",
        "        # AR coefficient (alpha): e_{k+1} = alpha*e_k + w_k\n",
        "        self.alpha = 0.5\n",
        "\n",
        "        # -- Covariances / Variances --\n",
        "        self.sigma_x_sq = 1.0   # Variance of Brownian increments per unit time\n",
        "        self.sigma_w_sq = 1.0   # Variance of noise innovations w_k\n",
        "        self.sigma_out_sq = 1.0 # Additional robust outlier penalty\n",
        "\n",
        "        # -- For robust weighting of outliers\n",
        "        self.kappa = 2.5  # Controls how strongly we clamp large residuals\n",
        "\n",
        "        # We store the time of the last update (if needed)\n",
        "        self.t_prev = 0.0\n",
        "\n",
        "    def update(self, x: float, dt: float):\n",
        "        \"\"\"\n",
        "        Assimilate a new observation x, after dt time has passed since the last observation.\n",
        "\n",
        "        The key idea is to treat:\n",
        "          - The latent state as a random walk (Brownian motion).\n",
        "          - Observations as x = x_true + e, where e is AR(1) noise with occasional outliers.\n",
        "        We adaptively learn alpha, sigma_x_sq, sigma_w_sq, etc.\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.has_first_obs:\n",
        "            # First observation: initialize filter\n",
        "            self.x_hat = x\n",
        "            self.has_first_obs = True\n",
        "            self.t_prev = dt\n",
        "            return\n",
        "\n",
        "        # 1) Predicted AR(1) noise\n",
        "        self.e_hat = self.alpha * self.e_hat\n",
        "\n",
        "        # 2) Compute residual = observed - predicted\n",
        "        residual = x - (self.x_hat + self.e_hat)\n",
        "\n",
        "        # 3) Robust weighting for outliers\n",
        "        #    If the residual is large relative to typical noise scale, reduce its influence.\n",
        "        residual_scale = max((self.sigma_x_sq + self.sigma_w_sq)**0.5, 1e-9)\n",
        "        norm_res = abs(residual) / residual_scale\n",
        "        robust_weight = min(1.0, self.kappa / max(norm_res, 1e-9))\n",
        "\n",
        "        # 4) Compute a scalar \"Kalman-like\" gain K\n",
        "        #    We'll define measurement variance ~ sigma_out_sq\n",
        "        #    We'll define process variance ~ sigma_x_sq*dt + sigma_w_sq\n",
        "        #    Then we clamp by the robust weight.\n",
        "        P_x = self.sigma_x_sq * dt\n",
        "        P_e = self.sigma_w_sq\n",
        "        var_meas = P_x + P_e + self.sigma_out_sq\n",
        "        K = ((P_x + P_e) / var_meas) * robust_weight\n",
        "\n",
        "        # 5) State update\n",
        "        alpha_x = 0.8\n",
        "        alpha_e = 0.2\n",
        "        self.x_hat += alpha_x * K * residual\n",
        "        self.e_hat += alpha_e * K * residual\n",
        "\n",
        "        # 6) Online updates of parameters\n",
        "        #    (a) alpha: we do a naive gradient step based on e_{k+1} ~ alpha*e_k\n",
        "        lr_alpha = 0.001\n",
        "        est_e = x - self.x_hat  # new implied noise\n",
        "        if abs(self.e_hat) > 1e-9:\n",
        "            new_alpha_est = est_e / self.e_hat\n",
        "            # clamp alpha to [0, 1)\n",
        "            new_alpha_est = max(0.0, min(0.99, new_alpha_est))\n",
        "            self.alpha = (1 - lr_alpha)*self.alpha + lr_alpha*new_alpha_est\n",
        "\n",
        "        #    (b) sigma_x_sq: measure the magnitude of \"update\" to x_hat over dt\n",
        "        lr_var = 0.001\n",
        "        increment = K * residual\n",
        "        incr_per_dt = increment / max(dt, 1e-9)\n",
        "        est_sigma_x_sq = incr_per_dt**2\n",
        "        self.sigma_x_sq = (1 - lr_var)*self.sigma_x_sq + lr_var*est_sigma_x_sq\n",
        "\n",
        "        #    (c) sigma_w_sq: measure the magnitude of \"noise\" increment in e_hat\n",
        "        noise_innov = self.e_hat - (self.alpha * (self.e_hat - alpha_e*K*residual))\n",
        "        est_sigma_w_sq = noise_innov**2\n",
        "        self.sigma_w_sq = (1 - lr_var)*self.sigma_w_sq + lr_var*est_sigma_w_sq\n",
        "\n",
        "        #    (d) sigma_out_sq: measure residual magnitude\n",
        "        est_sigma_out_sq = residual**2\n",
        "        self.sigma_out_sq = (1 - lr_var)*self.sigma_out_sq + lr_var*est_sigma_out_sq\n",
        "\n",
        "        self.t_prev += dt\n",
        "\n",
        "    def get_mean(self):\n",
        "        if not self.has_first_obs:\n",
        "            return None\n",
        "        return self.x_hat\n"
      ],
      "metadata": {
        "id": "94ZB6aj0U5tV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User run the following cell\n",
        "(The functions would be imported from elsewhere so as not to clutter the notebook)"
      ],
      "metadata": {
        "id": "mP6YrWeaQ7s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def instantiation_feedback():\n",
        "    try:\n",
        "       nc = Nowcast()\n",
        "    except Exception as e:\n",
        "        # TODO: Capture the traceback and produce a prompt telling LLM how to fix it\n",
        "        import traceback\n",
        "        tb_str = traceback.format_exc()\n",
        "        # Provide instructions or store them in a variable\n",
        "        # e.g., \"prompt_for_llm\" could be a string that includes your instructions:\n",
        "        prompt_for_llm = (\n",
        "            f\"An error occurred while trying to instantiate nowcast:\\n{tb_str}\\n\"\n",
        "            \"Please investigate the stack trace and suggest a fix.\"\n",
        "        )\n",
        "\n",
        "\n",
        "def unit_test_feedback():\n",
        "    \"\"\"\n",
        "    Run the nowcaster.\n",
        "\n",
        "    Creates an instance of Nowcast and attempts to run the unit_test_nowcast\n",
        "    function. If any exception occurs, capture the traceback and use it to\n",
        "    generate feedback for the LLM on how to fix the problem. Otherwise returns None.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    nc = Nowcast()\n",
        "    try:\n",
        "        example_xs = np.cumsum(np.random.randn(100)) + np.random.randn(100)\n",
        "        for x in example_xs:\n",
        "            nc.update(x)\n",
        "            y = nx.get_mean()\n",
        "        # Optionally, return or print 'feedback' if needed\n",
        "        # return feedback\n",
        "    except Exception as e:\n",
        "        # TODO: Capture the traceback and produce a prompt telling LLM how to fix it\n",
        "        import traceback\n",
        "        tb_str = traceback.format_exc()\n",
        "        # Provide instructions or store them in a variable\n",
        "        # e.g., \"prompt_for_llm\" could be a string that includes your instructions:\n",
        "        prompt_for_llm = (\n",
        "            f\"An error occurred while running unit_test_nowcast:\\n{tb_str}\\n\"\n",
        "            \"Please investigate the stack trace and suggest a fix.\"\n",
        "        )\n",
        "        # You might log it or handle it however you see fit\n",
        "        # print(prompt_for_llm)\n",
        "        pass\n",
        "\n",
        "def statistical_test_feedback():\n",
        "     # Placeholder\n",
        "     return None\n",
        "\n",
        "\n",
        "def live_test_feedback():\n",
        "     # Placeholder\n",
        "     return None\n",
        "\n",
        "\n",
        "feedback = instantiation_feedback() or unit_test_feedback() or statistical_test_feedback() or live_test_feedback()\n",
        "\n",
        "print(feedback)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMqSPxRwSpsm",
        "outputId": "0dd13b42-7195-4ac0-b728-a1ed167a8650"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    }
  ]
}